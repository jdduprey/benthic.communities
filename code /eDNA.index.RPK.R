# ==================================================
# Calculating eDNA indices of abundance
# input data generated by Ramon Gallego @
# https://github.com/ramongallego/eDNA.and.Ocean.Acidification.Gallego.et.al.2020
# Last updated 04/26/2021
# TODO: Needs some QA from Ryan and/or Moncho 
# ==================================================
library('tidyverse')
library('dplyr')
library('ggplot2')

hash.annotated <- read.csv('../data/hash.annotated.csv') # Mocho's hashes with taxa info
events <- read.csv('../data/events.joe.format.csv') # Moncho's event/environmental params w/ dates reformatted
ASV.table <- read.csv('../data/ASV_table_all_together.csv') # miseq run number, hash, sample, nReads
taxonomy.table <- read.csv('../data/all.taxonomy.20190130.csv') # hash with taxa info, total reads, total reps?, total sites present

# get table with sample, nReads, hash, and taxa information - why do we lose hashes here? 
ASV.tax <- inner_join(ASV.table, taxonomy.table)

# ==================================================
# This is the step I am least confident in
# merge replicates
# ==================================================
by.hash.sample.w.reps <- ASV.tax %>%
  group_by(sample, species, Hash) %>% # group the columns you want to "leave alone"
  summarize(nReads=sum(nReads)) %>% # sum nReads
  separate(col=sample, into=c('sample','tech'), sep='[.]') %>% # make technical and biological reps into columns
  separate(col=sample, into=c("sample", "bio"), sep = 9) # so that I can merge them

by.hash.sample <- by.hash.sample.w.reps %>%
  group_by(sample, species, Hash) %>%
  summarize(nReads=sum(nReads)) # same summarize code as used above - is this correct? 

#RPK says: yes, this is correct if you are looking to sum reads across all technical and biological replicates
#this will take you from 9 instances of a sampling event (3 biol * 3 tech replicates) to 1 sample representing the sum of all of those, for each taxon


# ==================================================
# by.hash.sample has separate rows for ASVs that are the same taxa/species but different hash
# now I want to merge these so all ASVs for a taxa/species are grouped 
# ==================================================
by.sample.species <- by.hash.sample %>%
  group_by(sample, species) %>% 
  summarize(nReads=sum(nReads))   ##RPK says: this works fine, although of course you could have done this in the previous step by just excluding Hash from the grouping variables

write.csv(by.sample.species,"../data/by.sample.species.csv")

# ==================================================
# begin calculating inputs needed for eDNA index 
# ***max number of reads per sample*** - SHOULD THIS BE BASED ON A SINGLE HASH or SINGLE SPECIES? 
# ==================================================
# maxreads_j.HASH <- by.hash.sample %>%
#   group_by(sample) %>%
#   summarize(max_j=max(nReads))

##RPK -- you can do it by hash ( == sequence variant) or by species; either should be a valid thing to do, although they will give slightly different answers.
## I'd just do it by species for now.


# maxreads_j.SPECIES or maxreads_j.hash both work just give slightly different results - see above
maxreads_j.SPECIES <- by.sample.species %>%
  group_by(sample) %>%
  summarize(max_j=max(nReads))

# calculate ***total reads by species***
nreads_i <- by.sample.species %>%
  group_by(species) %>%
  summarize(Y_i=sum(nReads)) 

# ==================================================
# put together joint table to calculate eDNA index 
# ==================================================
# eDNA <- inner_join(by.sample.species, nreads_i)
# eDNA <- inner_join(eDNA, maxreads_j.HASH)

# actual eDNA index calculations, there is probably a way to make this more readable with tidyverse, sorry Ryan!
# formula @ https://www.nature.com/articles/s41598-019-48546-x
# eDNA$index <- (eDNA$nReads/eDNA$Y_i)/eDNA$max_j*(eDNA$nReads/eDNA$Y_i)
# eDNA$log.index <- log(eDNA$index)

##RPK -- the above is backwards, I think.
##you want to take the observed number of reads for a given species in a given sample, nReads, and 
##first divide it by the sum of all nReads in that same sample 
##then divide the resulting proportion by the max proportion you ever see in the data for that species

myIndex <- by.sample.species %>%
  group_by(sample) %>% 
  mutate(totalReads = sum(nReads),
         propReads = nReads/totalReads) %>% 
  group_by(species) %>% 
  mutate(eDNA_index = propReads/(max(propReads)))

myIndex$log_index <- log(myIndex$eDNA_index)  
#you can check this: each species should have a min of 0, a max of 1, and should have at least a single `1` in its observations
Index.check <- myIndex %>% 
  group_by(species) %>% 
  summarize(max(eDNA_index),
            min(eDNA_index))
#things that occur only once in the data will have both max and min of 1.  


####RPK stopped here, because let's get the above right before anything else...


# ==================================================
# ==================================================
# create useful table with just the taxa that Moncho classified as BENTHIC
# merge hashes by species
# ==================================================
species.annotated <- hash.annotated %>%
  distinct(species, .keep_all=TRUE) 
 

ben.community <- inner_join(species.annotated, myIndex)

ben.community <- ben.community %>%
  filter(benthos %in% c('BEN','Both')) %>%
  separate(col=sample, remove=FALSE, into=c("site", "date"), sep = 2)

ben.community <- inner_join(ben.community, events)

# ==================================================
# DATA VIZ 
# ==================================================

#barnacles <- ben.community %>%
#  filter(species %in% c('Balanus glandula', 
#                        'Semibalanus cariosus',))


jpeg("../figures/all.the.benthos.jpg", height = 30000, width = 1000)
ggplot(data=ben.community, aes(x=pH_new, y=log.index, colour=site)) +
  geom_point() +
  facet_wrap(~ species, ncol=3)
dev.off()

#jpeg("../figures/lm.trial.jpg", height = 30000, width = 1000)
#ggplot(data=ben.community, aes(x=pH_new, y=log.index)) +
#  geom_point() +
#  geom_smooth(method = 'lm') +
#  facet_wrap(~ species, ncol=3)
#dev.off()

jpeg("../figures/time.series.jpg", heigh = 30000, width = 1000)
ggplot(data=ben.community, aes(x=date, y=log.index)) +
  geom_bar(stat='identity') +
  facet_wrap(~ species + site, ncol=3)
dev.off()

# species diversity time series ?   